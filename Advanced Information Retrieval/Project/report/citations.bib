
@misc{noauthor_what_nodate,
	title = {What is {Language} {Modeling}?},
	url = {https://www.techtarget.com/searchenterpriseai/definition/language-modeling},
	abstract = {Learn about language modeling, the different model types, and how they serve as the basis of all natural language processing (NLP) tasks. Find out more about uses of language modeling with examples of how it's used.},
	language = {en},
	urldate = {2023-01-21},
	journal = {Enterprise AI},
}

@misc{fallah_overview_2021,
	title = {An {Overview} of {Different} {Transformer}-based {Language} {Models}},
	url = {https://techblog.ezra.com/an-overview-of-different-transformer-based-language-models-c9d3adafead8},
	abstract = {In a previous article, we discussed the importance of embedding models and went through the details of some commonly used algorithms. We…},
	language = {en},
	urldate = {2023-01-21},
	journal = {Medium},
	author = {Fallah, Maryam},
	month = mar,
	year = {2021},
}

@misc{noauthor_better_2019,
	title = {Better {Language} {Models} and {Their} {Implications}},
	url = {https://openai.com/blog/better-language-models/},
	abstract = {We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization.},
	language = {en},
	urldate = {2023-01-21},
	journal = {OpenAI},
	month = feb,
	year = {2019},
}

@misc{noauthor_steganography_2019,
	title = {Steganography {Tutorial} {\textbar} {A} {Complete} {Guide} {For} {Beginners}},
	url = {https://www.edureka.co/blog/steganography-tutorial},
	abstract = {Steganography is hiding data in plain sight and this steganography tutorial will help you understand how to keep data secure using steganography},
	language = {en-US},
	urldate = {2023-01-21},
	journal = {Edureka},
	month = jan,
	year = {2019},
}

@inproceedings{prasad2011new,
	title={A new approach to Telugu text steganography},
	author={Prasad, Ramineni Siva Ram and Alla, Kalavathi},
	booktitle={2011 IEEE Symposium on Wireless Technology and Applications (ISWTA)},
	pages={60--65},
	year={2011},
	organization={IEEE}
}

@article{bennett2004linguistic,
	title={Linguistic steganography: Survey, analysis, and robustness concerns for hiding information in text},
	author={Bennett, Krista},
	year={2004},
	publisher={Citeseer}
}

@article{hamdan2016ah4s,
	title={AH4S: an algorithm of text in text steganography using the structure of omega network},
	author={Hamdan, Abdullah M and Hamarsheh, Ala},
	journal={Security and Communication Networks},
	volume={9},
	number={18},
	pages={6004--6016},
	year={2016},
	publisher={Wiley Online Library}
}

@article{chen2015microsoft,
	title={Microsoft coco captions: Data collection and evaluation server},
	author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	journal={arXiv preprint arXiv:1504.00325},
	year={2015}
}

@misc{noauthor_translation_nodate,
	title = {Translation {Task} - {ACL} 2017 {Second} {Conference} on {Machine} {Translation}},
	url = {https://www.statmt.org/wmt17/translation-task.html},
	urldate = {2023-01-21},
}

@inproceedings{yang2020gan,
	title={GAN-TStega: Text steganography based on generative adversarial networks},
	author={Yang, Zhongliang and Wei, Nan and Liu, Qinghe and Huang, Yongfeng and Zhang, Yujin},
	booktitle={Digital Forensics and Watermarking: 18th International Workshop, IWDW 2019, Chengdu, China, November 2--4, 2019, Revised Selected Papers 18},
	pages={18--31},
	year={2020},
	organization={Springer}
}

@article{kang2020generative,
  title={Generative text steganography based on LSTM network and attention mechanism with keywords},
  author={Kang, Huixian and Wu, Hanzhou and Zhang, Xinpeng},
  journal={Electronic Imaging},
  volume={2020},
  number={4},
  pages={291--1},
  year={2020},
  publisher={Society for Imaging Science and Technology}
}

@misc{noauthor_language_nodate,
	title = {Language {Modeling} with nn.{Transformer} and {TorchText} — {PyTorch} {Tutorials} 1.13.1+cu117 documentation},
	url = {https://pytorch.org/tutorials/beginner/transformer\_tutorial.html},
	urldate = {2023-01-24},
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}